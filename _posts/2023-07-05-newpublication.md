---
layout: post
title:  "New Paper Published by Our Laboratory!"
date:   2023-07-05
categories: general
headline: Check out our new paper!
---

We are thrilled to announce the publication of a new research paper by our laboratory! This momentous achievement represents the culmination of hard work, dedication, and collaborative efforts from our brilliant team of researchers and scholars.

ðŸ“– Title: Investigation of Kriging-based SAEAsâ€™ metamodel samples for computationally expensive optimization problems
ðŸ‘¥ Authors: MÃ´nica ValadÃ£o, AndrÃ© Maravilha, and Lucas Batista
ðŸ“… Journal: Evolutionary Intelligence
ðŸ”— DOI/Link: [10.1007/s12065-023-00862-y](https://doi.org/10.1007/s12065-023-00862-y)

Check out the abstract: *"Surrogate model assisted evolutionary algorithms (SAEAs) are strategies widely applied to deal with computationally expensive optimization problems (CEOPs). These methods employ metamodels to drive an evolutionary algorithm (EA) to promising design regions where new evaluations on the true-objective function must be performed. To do this, SAEAs are required to handle the challenge of training a metamodel to improve its predictions. The reliability of a metamodel is strongly related to the samples used for its training. Despite this, several SAEAs are proposed without concern about the sampling strategy employed. The ideal situation is to obtain a sample not far away from the solutions predicted on the metamodel. In this sense, the contribution/novelty of this paper regards an investigative study to compare five strategies for defining the metamodel sample in a proposed SAEA Framework (SAEA/F). The SAEA/F uses a one-dimensional Ordinary Kriging (OK) metamodel, and an expected improvement (EI) merit function is applied to define on which solutions to spend the budget of true-function evaluation. In this investigation, each strategy is incorporated into SAEA/F and then used to solve a set of analytical functions of single-objective optimization problems. The computational results suggest that two of the five sampling strategies stand out the best. The first strategy chooses those solutions with the lowest distance to the centroid of the population of solutions, and the second selects the newest solutions evaluated on true-objective function. The results highlight the potential of these approaches for solving expensive optimization problems since they speed up the algorithm convergence to improved solutions."*

You can access the full paper through the provided DOI/link, and we encourage you to read, share, and engage with the research.

Once again, we express our gratitude to everyone who played a part in making this publication a reality. We remain committed to advancing scientific knowledge and look forward to sharing more exciting research from our laboratory in the future!

Stay tuned for more updates!